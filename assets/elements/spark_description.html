<div align="center">
Production Realtime & Batch: My Experiences
</div>
<div class="row">
    <div class="column">
        <div class="gridcontent">
            <strong>Analytics</strong><br/>Construction of a world-class firmware-analytic statistical analysis batch-work pipeline through AWS Glue.
        </div>
        <div class="gridcontent">
            <strong>Risk Enumeration</strong><br/>Market-leading enumeration of firmware risk generated in batch and realtime based on statistical findings.
        </div>
        <div class="gridcontent">
            <strong>Thoughtful Modeling</strong><br/>Preparation of data after exploration for more accurate statistics and metrics at the other side of the pipe.
        </div>
        <div class="gridcontent">
            <strong>Diving Deep</strong><br/>Long hours spent understanding the engine underlying Spark & Spark's configuration itself.
        </div>
    </div>
    <div class="column">
        <div class="gridcontent">
            <strong>Scalability</strong><br/>Performance in batch using AWS Glue, and in real-time using either EMR or dynamically scaling clusters in ECS.
        </div>
        <div class="gridcontent">
            <strong>Extensibility</strong><br/>Full-fledged Spark-only data ETL libraries custom-crafted for statistical analysis on a massive dataset.
        </div>
        <div class="gridcontent">
            <strong>Test-ability</strong><br/>Custom PySpark unit testing framework coupled with scripts for auto-generation of ready-to-use test DataFrames and RDDs, as desired.
        </div>
        <div class="gridcontent">
            <strong>Flexibility</strong><br/>Connecting to your data as JDBC or on HDFS or as Parquet or as ORC -- transferring it to any of them -- and back again -- no problems! ( Just be careful with your truncate/load ops! )
        </div>
    </div>
</div>